{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook's aim is to transform the pre-processed documents into vectors and do a supervised analysis\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jeremynadal33/categorize_question_API/blob/master/supervised_approach.ipynb)\n",
    "\n",
    "\n",
    "## Here, are compared supervised methods : \n",
    "## We will compare the results for two different vectorization methods : Bag of Word and Tfidf\n",
    "First, import the relevant libraries : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import datetime as datetime\n",
    "\n",
    "## My script : \n",
    "from function import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific libraries : \n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer # BoW\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Tfidf\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/Users/jeremynadal/Documents/Formation OC IML/P5-API/'\n",
    "input_dir = root_dir + 'inputs/'\n",
    "png_dir = root_dir + 'pngs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39409, 3)\n",
      "Tags              object\n",
      "processed_text    object\n",
      "nb_tags            int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>nb_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['c#']</td>\n",
       "      <td>['convert', 'double', 'c#', 'convert', 'double...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['c#', '.net']</td>\n",
       "      <td>['c#', 'calculate', 'someone', 'age', 'base', ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['c#']</td>\n",
       "      <td>['calculate', 'time', 'c#', 'calculate', 'time...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['html']</td>\n",
       "      <td>['determine', 'user', 'timezone', 'determine',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['.net']</td>\n",
       "      <td>['difference', 'mathfloor', 'mathtruncate', 'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Tags                                     processed_text  nb_tags\n",
       "0          ['c#']  ['convert', 'double', 'c#', 'convert', 'double...        1\n",
       "1  ['c#', '.net']  ['c#', 'calculate', 'someone', 'age', 'base', ...        2\n",
       "2          ['c#']  ['calculate', 'time', 'c#', 'calculate', 'time...        1\n",
       "3        ['html']  ['determine', 'user', 'timezone', 'determine',...        1\n",
       "4        ['.net']  ['difference', 'mathfloor', 'mathtruncate', 'd...        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(input_dir+'processed_dataset.csv')\n",
    "\n",
    "print(data.shape)\n",
    "print(data.dtypes)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reforme_tags_processed_text(data):\n",
    "    tags = []\n",
    "    processed_text = []\n",
    "    for indx in range(data.shape[0]):\n",
    "        new_tags = []\n",
    "        new_processed = []\n",
    "        \n",
    "        split = data['Tags'][indx].split(',')\n",
    "        for nb_tags in range(data['nb_tags'][indx]):    \n",
    "            to_append = re.sub('[\\[\\]\\'\\\"!*+-]','',split[nb_tags]).replace('\\\\','').replace(' ','')\n",
    "            if not to_append in ['',' '] : new_tags.append(to_append)\n",
    "        tags.append(new_tags)\n",
    "        \n",
    "        text = data['processed_text'][indx].split(',')\n",
    "        for i in range(len(text)):\n",
    "            to_append = re.sub('[\\[\\]\\'\\\"!*+-:.]','',text[i]).replace('\\\\','').replace(' ','')\n",
    "            if not to_append in ['',' '] : new_processed.append(to_append)\n",
    "        processed_text.append(new_processed)\n",
    "        \n",
    "    data['Tags'] = tags\n",
    "    data['processed_text'] = processed_text\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>nb_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[c#]</td>\n",
       "      <td>[convert, double, c#, convert, double, c#, wan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[c#, .net]</td>\n",
       "      <td>[c#, calculate, someone, age, base, datetime, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[c#]</td>\n",
       "      <td>[calculate, time, c#, calculate, time, c#, giv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[html]</td>\n",
       "      <td>[determine, user, timezone, determine, user, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[.net]</td>\n",
       "      <td>[difference, mathfloor, mathtruncate, differen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tags                                     processed_text  nb_tags\n",
       "0        [c#]  [convert, double, c#, convert, double, c#, wan...        1\n",
       "1  [c#, .net]  [c#, calculate, someone, age, base, datetime, ...        2\n",
       "2        [c#]  [calculate, time, c#, calculate, time, c#, giv...        1\n",
       "3      [html]  [determine, user, timezone, determine, user, t...        1\n",
       "4      [.net]  [difference, mathfloor, mathtruncate, differen...        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = reforme_tags_processed_text(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tags(tags):\n",
    "    res = []\n",
    "    for i in range(len(tags)):\n",
    "        for j in range(len(tags[i])):\n",
    "            res.append(tags[i][j])\n",
    "            \n",
    "    return pd.Series(res)\n",
    "\n",
    "tags = get_all_tags(data['Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = np.unique(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in unique_tags : \n",
    "    data[tag] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremynadal/anaconda3/envs/fieldbox/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for idx in data.index:\n",
    "    for id_tag in range(data['nb_tags'][idx]):\n",
    "        data[data['Tags'][idx][id_tag]][idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>nb_tags</th>\n",
       "      <th>.net</th>\n",
       "      <th>android</th>\n",
       "      <th>arrays</th>\n",
       "      <th>asp.net</th>\n",
       "      <th>bash</th>\n",
       "      <th>c</th>\n",
       "      <th>c#</th>\n",
       "      <th>...</th>\n",
       "      <th>linux</th>\n",
       "      <th>mysql</th>\n",
       "      <th>objectivec</th>\n",
       "      <th>php</th>\n",
       "      <th>python</th>\n",
       "      <th>regex</th>\n",
       "      <th>sql</th>\n",
       "      <th>sqlserver</th>\n",
       "      <th>string</th>\n",
       "      <th>windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[c#]</td>\n",
       "      <td>[convert, double, c#, convert, double, c#, wan...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[c#, .net]</td>\n",
       "      <td>[c#, calculate, someone, age, base, datetime, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[c#]</td>\n",
       "      <td>[calculate, time, c#, calculate, time, c#, giv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[html]</td>\n",
       "      <td>[determine, user, timezone, determine, user, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[.net]</td>\n",
       "      <td>[difference, mathfloor, mathtruncate, differen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tags                                     processed_text  nb_tags  \\\n",
       "0        [c#]  [convert, double, c#, convert, double, c#, wan...        1   \n",
       "1  [c#, .net]  [c#, calculate, someone, age, base, datetime, ...        2   \n",
       "2        [c#]  [calculate, time, c#, calculate, time, c#, giv...        1   \n",
       "3      [html]  [determine, user, timezone, determine, user, t...        1   \n",
       "4      [.net]  [difference, mathfloor, mathtruncate, differen...        1   \n",
       "\n",
       "   .net  android  arrays  asp.net  bash  c  c#  ...  linux  mysql  objectivec  \\\n",
       "0     0        0       0        0     0  0   1  ...      0      0           0   \n",
       "1     1        0       0        0     0  0   1  ...      0      0           0   \n",
       "2     0        0       0        0     0  0   1  ...      0      0           0   \n",
       "3     0        0       0        0     0  0   0  ...      0      0           0   \n",
       "4     1        0       0        0     0  0   0  ...      0      0           0   \n",
       "\n",
       "   php  python  regex  sql  sqlserver  string  windows  \n",
       "0    0       0      0    0          0       0        0  \n",
       "1    0       0      0    0          0       0        0  \n",
       "2    0       0      0    0          0       0        0  \n",
       "3    0       0      0    0          0       0        0  \n",
       "4    0       0      0    0          0       0        0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets separate the data into train and test for both bow and tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "(39409, 1000)\n"
     ]
    }
   ],
   "source": [
    "bow_vectorizer = CountVectorizer(tokenizer = lambda x: x,\n",
    "                                 preprocessor = lambda x: x,\n",
    "                                 lowercase = False,\n",
    "                                 max_features = 1000,\n",
    "                                 binary = True,\n",
    "                                 max_df = 0.9\n",
    "                                 )  \n",
    "bow_X = bow_vectorizer.fit_transform(data['processed_text'])\n",
    "print(len(bow_vectorizer.get_feature_names()))\n",
    "print(bow_X.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(tokenizer = lambda x: x,\n",
    "                                   preprocessor = lambda x: x,\n",
    "                                   lowercase = False,\n",
    "                                   max_features = 1000,\n",
    "                                   max_df = 0.9\n",
    "                                   )  \n",
    "tfidf_X = tfidf_vectorizer.fit_transform(data['processed_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset : X.shape =  (31527, 1000)  Y.shape =  (31527, 24)\n",
      "Test dataset : X.shape =  (7882, 1000)  Y.shape =  (7882, 24)\n"
     ]
    }
   ],
   "source": [
    "X_train_bow, X_test_bow, y_train_multi, y_test_multi = train_test_split(bow_X.toarray(), \n",
    "                                                                     data[unique_tags], \n",
    "                                                                     test_size=0.2, \n",
    "                                                                     random_state=42)\n",
    "X_train_tfidf, X_test_tfidf, y_train_tags, y_test_tags = train_test_split(tfidf_X.toarray(), \n",
    "                                                                            data['Tags'], \n",
    "                                                                            test_size=0.2, \n",
    "                                                                            random_state=42)\n",
    "print('Train dataset : X.shape = ' , X_train_bow.shape, ' Y.shape = ', y_train_bow.shape)\n",
    "print('Test dataset : X.shape = ' , X_test_bow.shape, ' Y.shape = ', y_test_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We define some metrics to compare the different models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    assert x.shape == y.shape , 'x and y doesnt have same shape'\n",
    "    assert len(x.shape)==2 , 'x and y must be matrixes [nb_samp,x], if only 1 sample use : np.reshape(1,-1)'\n",
    "    cosin = []\n",
    "    for idx in range(x.shape[0]):\n",
    "        if (np.dot(x[idx], x[idx]) !=0 and np.dot(y[idx], y[idx]) != 0 ) :\n",
    "            cosin.append(np.dot(x[idx], y[idx]) / (np.sqrt(np.dot(x[idx], x[idx])) * np.sqrt(np.dot(y[idx], y[idx]))))\n",
    "        elif (np.dot(x[idx], x[idx]) ==0 and np.dot(y[idx], y[idx]) == 0 ) : \n",
    "            cosin.append(1)\n",
    "        else:\n",
    "            cosin.append(-1)\n",
    "    return np.mean(cosin)\n",
    "\n",
    "def print_metrics(y_true, pred):\n",
    "    '''Prints and return a summary of results'''\n",
    "    y_true = np.array(y_true)\n",
    "    pred = np.array(pred)\n",
    "    assert y_true.shape == pred.shape, 'arrays doesnt have same shape'\n",
    "    \n",
    "    res = [metrics.accuracy_score(y_true, pred),\n",
    "           metrics.hamming_loss(y_true,pred),\n",
    "           precision_score(y_true, pred, average='micro'),\n",
    "           recall_score(y_true, pred, average='micro'),\n",
    "           f1_score(y_true, pred, average='micro'),\n",
    "           cosine_similarity(y_true,pred)]\n",
    "    \n",
    "    print(\"Accuracy :{:.3}\\nHamming loss :{:.4}\\n\\nMicro-averaged quality metrics :\\nPrecision :{:.3}\\nRecall :{:.3}\\nF1-score :{:.3}\\nCosine similarity : {:.3}\".format(*res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets compare different models on both vectorizers (bow and tfidf)\n",
    "* SGD \n",
    "* Logistic regression \n",
    "* Random Forest\n",
    "* XGBoost \n",
    "* LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :0.454\n",
      "Hamming loss :0.0293\n",
      "\n",
      "Micro-averaged quality metrics :\n",
      "Precision :0.857\n",
      "Recall :0.55\n",
      "F1-score :0.67\n",
      "Cosine similarity : 0.281\n",
      "Time taken to run this cell : 38.405165999999994\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l1'))\n",
    "classifier.fit(X_train_bow, y_train_multi)\n",
    "predictions = classifier.predict(X_test_bow)\n",
    "\n",
    "\n",
    "res = print_metrics(y_test_multi, predictions)\n",
    "print(\"Time taken to run this cell :\", time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :0.513\n",
      "Hamming loss :0.02672\n",
      "\n",
      "Micro-averaged quality metrics :\n",
      "Precision :0.821\n",
      "Recall :0.646\n",
      "F1-score :0.723\n",
      "Cosine similarity : 0.489\n",
      "Time taken to run this cell : 163.64250900000002\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "classifier = OneVsRestClassifier(LogisticRegression(max_iter = 1000))\n",
    "classifier.fit(X_train_bow, y_train_multi)\n",
    "predictions = classifier.predict(X_test_bow)\n",
    "\n",
    "\n",
    "res = print_metrics(y_test_multi, predictions)\n",
    "print(\"Time taken to run this cell :\", time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.process_time()\n",
    "classifier = OneVsRestClassifier(LogisticRegression(max_iter = 1000))\n",
    "classifier.fit(X_train_bow, y_train_multi)\n",
    "predictions = classifier.predict(X_test_bow)\n",
    "\n",
    "\n",
    "res = print_metrics(y_test_multi, predictions)\n",
    "print(\"Time taken to run this cell :\", time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_from_tag = lambda tag: ('a' if tag[0].lower() == 'j' else tag[0].lower()) if tag[0].lower() in ['n', 'r', 'v'] else 'n'\n",
    "\n",
    "def handle_body(text, \n",
    "                #tokenizer = nltk.RegexpTokenizer(r'\\w+'), \n",
    "                stop_words = nltk.corpus.stopwords.words(\"english\"), \n",
    "                lemmatizer = nltk.stem.WordNetLemmatizer()  ):\n",
    "    \n",
    "    POS_to_rm = ['RB','RBR','RBS','JJ','JJR','JJS','CD'] #Removing adverbs and adjectives and digits\n",
    "    stop_words += ['.','€','$','?','\\'s',',',':',';','=','+','-']  \n",
    "    \n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    tokens = nltk.word_tokenize( soup.get_text().lower() )\n",
    "    \n",
    "    tokens = [re.sub('[.,?!)()<>:;\\ \\\"\\'\\]\\[+-=\\{\\}\\|^*@&`’]','',token).replace('\\\\','').replace('?','') for token in tokens]\n",
    "    tokens = [token for token in tokens if token != '']\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "\n",
    "    tokens = [ tokens[i] for i in range(len(tokens)) if ( (not tokens[i] in stop_words) and (not tags[i][1] in POS_to_rm ) )]\n",
    "    \n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    \n",
    "    result = [lemmatizer.lemmatize(tokens[i], pos=pos_from_tag(tags[i][1])) for i in range(len(tokens))]\n",
    "    \n",
    "    return result \n",
    "\n",
    "def handle_title(text,\n",
    "                 stop_words = nltk.corpus.stopwords.words(\"english\"), \n",
    "                 lemmatizer = nltk.stem.WordNetLemmatizer()  ): \n",
    "    \n",
    "    POS_to_rm = ['RB','RBR','RBS','JJ','JJR','JJS'] #Removing adverbs and adjectives\n",
    "    stop_words += ['.','€','$','?','\\'s',',',':',';','=','+','-']  \n",
    "    \n",
    "    tokens = re.split(' ', text.lower())\n",
    "    tokens = [re.sub('[.,?!)()<>:;\\ \\\"\\'\\]\\[+-=\\{\\}\\|^*@&`’]','',token).replace('\\\\','').replace('?','') for token in tokens]\n",
    "\n",
    "    tokens = [token for token in tokens if token != '']\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    \n",
    "    tokens = [ tokens[i] for i in range(len(tokens)) if ( (not tokens[i] in stop_words) and (not tags[i][1] in POS_to_rm ) )]\n",
    "    \n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    \n",
    "    result = [lemmatizer.lemmatize(tokens[i], pos=pos_from_tag(tags[i][1])) for i in range(len(tokens))]\n",
    "    \n",
    "    return result \n",
    "\n",
    "def preprocess_text(body, title = None):\n",
    "    body = handle_body(body)\n",
    "    if title :\n",
    "        title = handle_title(title)\n",
    "        body = title + title + body\n",
    "    return body\n",
    "\n",
    "\n",
    "def predict_new_sentence(text, vectorizer, model, all_tags, title = None):\n",
    "    all_tags = np.array(all_tags)\n",
    "    text = np.array(preprocess_text(text, title=title)).reshape(1, -1)\n",
    "    text = vectorizer.transform(text)\n",
    "    pred = model.predict(text)\n",
    "    \n",
    "    assert pred[0].shape == all_tags.shape, 'the passed tags doesnot have same shape as model output'\n",
    "    idx = [idx for idx in range(len(all_tags)) if pred[0][idx]==1]\n",
    "    return all_tags[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Hi, my name is Jack and I love potatoes'\n",
    "title = ''\n",
    "predict_new_sentence(text, bow_vectorizer, classifier, unique_tags, title=title )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['.net', 'android', 'arrays', 'asp.net', 'bash', 'c', 'c#', 'css',\n",
       "       'git', 'html', 'iphone', 'java', 'javascript', 'jquery', 'linux',\n",
       "       'mysql', 'objectivec', 'php', 'python', 'regex', 'sql',\n",
       "       'sqlserver', 'string', 'windows'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "test = mlb.fit_transform(y_train_tags)\n",
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5770          [c#, sqlserver]\n",
       "36859            [javascript]\n",
       "13756             [html, css]\n",
       "10742    [javascript, arrays]\n",
       "22065                  [java]\n",
       "                 ...         \n",
       "6265                 [iphone]\n",
       "11284             [sqlserver]\n",
       "38158        [sql, sqlserver]\n",
       "860             [c#, asp.net]\n",
       "15795                [python]\n",
       "Name: Tags, Length: 31527, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
